# BLE Temperature Monitoring Configuration

# BLE scanning configuration
ble:
  # List of sensors to monitor
  # Note: BLE scanning runs continuously; sensors broadcast every 2-5 seconds
  sensors:
    - name: Sypialnia
      id: 1
      macAddress: A4:C1:38:ED:C0:21
    - name: Salon
      id: 2
      macAddress: A4:C1:38:26:E2:4C
    - name: ≈Åazienka
      id: 3
      macAddress: A4:C1:38:F1:2D:0D
    - name: Balkon
      id: 4
      macAddress: A4:C1:38:3E:5F:D1

# Netatmo thermostat integration
netatmo:
  # Enable Netatmo thermostat data collection
  enabled: true

  # Netatmo OAuth2 credentials
  # Get these from https://dev.netatmo.com/apps
  # IMPORTANT: Use environment variables for sensitive data
  clientId: ""  # or use NETATMO_CLIENT_ID env var
  clientSecret: ""  # or use NETATMO_CLIENT_SECRET env var
  refreshToken: ""  # or use NETATMO_REFRESH_TOKEN env var

  # Interval between Netatmo API fetches in seconds (minimum: 1, recommended: 60)
  # Note: Netatmo rate limits apply - don't set too low
  fetchIntervalSeconds: 60

# Prometheus metrics push configuration
prometheus:
  # Interval between metric pushes in seconds (minimum: 1)
  pushIntervalSeconds: 30

  # Prometheus remote_write endpoint URL
  # For Grafana Cloud, use: https://prometheus-prod-XX-YY-ZZ.grafana.net/api/prom/push
  prometheusUrl: "https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push"

  # Prometheus basic auth username (Grafana Cloud instance ID)
  prometheusUsername: "83165"

  # Grafana Cloud password (API key)
  # IMPORTANT: Use PROMETHEUS_PASSWORD environment variable instead of storing here
  prometheusPassword: ""

  # Start pushing at even second boundaries (improves alignment in time series)
  startAtEvenSecond: true

  # Ring buffer size (number of readings to buffer before push)
  bufferSize: 100000

  # Batch size for pushing metrics (number of readings per batch, default: 1000)
  # Larger batches are more efficient but may hit size limits on the receiving end
  batchSize: 1000

# OpenTelemetry tracing and metrics configuration
opentelemetry:
  # Enable OpenTelemetry instrumentation
  enabled: true

  # Service name for traces and metrics (identifies this service in Grafana)
  serviceName: "thermostats-ble"

  # Service version (appears in traces and metrics)
  serviceVersion: "1.0.0"

  # Deployment environment (e.g., production, staging, development)
  environment: "production"

  # OTLP trace exporter configuration
  traces:
    # Enable trace collection and export
    enabled: true

    # OTLP endpoint for traces (Grafana Cloud Tempo endpoint)
    # Format: https://otlp-gateway-{region}.grafana.net/otlp
    # or use OTEL_EXPORTER_OTLP_TRACES_ENDPOINT env var
    endpoint: ""

    # Authentication headers for Grafana Cloud
    # Use OTEL_EXPORTER_OTLP_TRACES_HEADERS env var for security
    # Format: "Authorization=Basic base64(instanceId:grafanaCloudAccessToken)"
    headers: {}

    # Sampling configuration
    # samplingRatio: 1.0 means trace 100% of requests (adjust for high volume)
    samplingRatio: 1.0

    # Batch processor configuration
    batch:
      # Maximum time to wait before exporting a batch (milliseconds)
      scheduleDelayMillis: 5000
      # Maximum batch size
      maxQueueSize: 2048
      # Maximum export batch size
      maxExportBatchSize: 512

  # OTLP metrics exporter configuration
  metrics:
    # Enable metrics collection and export
    enabled: true

    # OTLP endpoint for metrics (can be same as traces or different)
    # Use OTEL_EXPORTER_OTLP_METRICS_ENDPOINT env var
    endpoint: ""

    # Authentication headers (same format as traces)
    headers: {}

    # Metric collection interval in milliseconds
    intervalMillis: 30000

    # Enable runtime metrics (Go runtime stats: goroutines, memory, GC)
    enableRuntimeMetrics: true

  # Resource attributes (additional metadata attached to all traces and metrics)
  resourceAttributes:
    # Example: Add custom attributes
    # deployment.datacenter: "us-central1"
    # host.type: "raspberry-pi"

# Logging configuration
logging:
  # Log format: "console" (human-readable) or "json" (structured)
  # Use "console" for development, "json" for production
  logFormat: "console"

  # Log level: "debug", "info", "warn", "error"
  logLevel: "info"
